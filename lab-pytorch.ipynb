{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOlUQ2tr2V1M"
   },
   "source": [
    "# Exercises Dimensionality reduction\n",
    "\n",
    "\n",
    "In this exercise we will implement a variational auto-encoder (VAE). An auto-encoder encodes some input into a new and usually more compact representation which can be used to reconstruct the input data again. A VAE makes the assumption that the compact representation follows a probabilistic distribution (usually Gaussian) which makes it possible to sample new points and decode them into new data from a trained variational auto-encoder. The \"variational\" part comes from the fact that these models are training through variational inference.\n",
    "\n",
    "The mathematical details of the training can be a bit challenging. However, we believe that probabilistic deep learning will be an important part of future machine learning, which is why we find it important to introduce the concepts.\n",
    "\n",
    "As background material we recommend reading Tutorial on Variational Autoencoder. For the implementation of the model you can read the article \"Auto-Encoding Variational Bayes\", Kingma & Welling, ICLR 2014: http://arxiv.org/pdf/1312.6114v10.pdf and \"Stochastic Backpropagation and Approximate Inference in Deep Generative Models\", Rezende et al, ICML 2014: http://arxiv.org/pdf/1401.4082v3.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZraSs2z2k7E"
   },
   "source": [
    "# VAE crash course\n",
    "\n",
    "Like the simple auto-encoder, VAEs consist of two parts as seen in the figure below where all arrows are non-linear mappings through a neural network. The two parts are the:\n",
    "\n",
    " * **Encoder** : Maps the input data into a probabilistic latent space, z, by defining the mean and variance parameters of a Gaussian distribution as non-linear functions of the input data x like:\n",
    "     - $q(z|x) = \\mathcal{N}(z|\\mu_\\theta(x), \\sigma_\\phi(x))$, which is called the approximate posterior or latent distribution. The parameters $\\mu_\\theta(x)$ (mean) and $\\log \\sigma_\\phi(x)^2$ (log-variance) are outputs from a hidden layer each.\n",
    " * **Decoder** (also known as generative part of the model): Conditioned on samples drawn from $z \\sim q(z|x)$ in the encoder the input data is reconstructed through the:\n",
    "     - $p(x|z)$, which is the conditional likelihood (generative distribution). This is the decoder that will reconstruct the data from the latent space z.\n",
    "\n",
    "### Training a VAE\n",
    "The VAE is similar to a deterministic autoencoder except that we assume that the latent units follows a distribution. Usually we just assume that the units are independent standard normally distributed (i.i.d.).\n",
    "\n",
    "Above we defined a lower bound on the log-likelihood of the data. We can train the model by maximising the lower bound w.r.t. the model parameters, weight matrices, through the stochastic gradient descent algorithm.  Feasible approximations of the expectations in the lower bound, $\\mathcal{L}(x)$, are obtained by evaluating the inside with samples drawn from the latent distribution, $z \\sim q(z|x) = \\mathcal{N}(z|\\mu_\\theta(x), \\sigma_\\phi(x)I)$ and dividing by the number of samples drawn. By using the _reparameterization trick_, $ \\mu_\\theta(x) + \\sigma_\\phi(x) \\cdot \\epsilon$, for the sampling procedure we can directly backpropogate gradients through the latent bottleneck and optimize the parameters w.r.t. the lower bound.\n",
    "\n",
    "### Setting up the network\n",
    "\n",
    "We define the network like an auto-encoder except that the bottleneck is the __sample_layer__ which samples the latent units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-qJh9zJY2mYv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 4073103.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 338585.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2242934.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 13626987.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "bs = 100 # Batch-size\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzNlK9De3Rb6",
    "outputId": "c8f11744-9aed-4d25-938a-9c5036356a69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc31): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc32): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc4): Linear(in_features=2, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "\n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "\n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vae.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "srn5Wfcm3hES"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We define the optimizer\n",
    "optimizer = optim.Adam(vae.parameters())\n",
    "\n",
    "# Assuming loss_function returns reconstruction loss and KL divergence as well\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    # Flatten the tensors if necessary\n",
    "    recon_x = recon_x.view(-1, 784)\n",
    "    x = x.view(-1, 784)\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD, BCE, KLD\n",
    "\n",
    "# Plotting function oif the loss terms\n",
    "def plot_losses(train_losses, recon_losses, kl_divergences):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Total Loss over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, recon_losses, label='Reconstruction Loss')\n",
    "    plt.plot(epochs, kl_divergences, label='KL Divergence')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Reconstruction Loss and KL Divergence over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Training function\n",
    "def train(epoch, device):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    recon_loss_total = 0\n",
    "    kl_loss_total = 0\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        loss, recon_loss, kl_loss = loss_function(recon_batch, data, mu, log_var)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        recon_loss_total += recon_loss.item()\n",
    "        kl_loss_total += kl_loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "\n",
    "    average_loss = train_loss / len(train_loader.dataset)\n",
    "    average_recon_loss = recon_loss_total / len(train_loader.dataset)\n",
    "    average_kl_loss = kl_loss_total / len(train_loader.dataset)\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, average_loss))\n",
    "    print('====> Epoch: {} Average reconstruction loss: {:.4f}'.format(epoch, average_recon_loss))\n",
    "    print('====> Epoch: {} Average KL divergence: {:.4f}'.format(epoch, average_kl_loss))\n",
    "\n",
    "    return average_loss, average_recon_loss, average_kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_mwpiBT79YIf"
   },
   "outputs": [],
   "source": [
    "def test(epoch, device):\n",
    "    vae.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    recon_loss_total = 0\n",
    "    kl_loss_total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for data, _ in test_loader:\n",
    "            data = data.to(device)\n",
    "\n",
    "            recon_batch, mu, log_var = vae(data)\n",
    "            loss, recon_loss, kl_loss = loss_function(recon_batch, data, mu, log_var)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            recon_loss_total += recon_loss.item()\n",
    "            kl_loss_total += kl_loss.item()\n",
    "\n",
    "    average_test_loss = test_loss / len(test_loader.dataset)\n",
    "    average_recon_loss = recon_loss_total / len(test_loader.dataset)\n",
    "    average_kl_loss = kl_loss_total / len(test_loader.dataset)\n",
    "\n",
    "    print('====> Test Epoch: {} Average loss: {:.4f}'.format(epoch, average_test_loss))\n",
    "    print('====> Test Epoch: {} Average reconstruction loss: {:.4f}'.format(epoch, average_recon_loss))\n",
    "    print('====> Test Epoch: {} Average KL divergence: {:.4f}'.format(epoch, average_kl_loss))\n",
    "\n",
    "    return average_test_loss, average_recon_loss, average_kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkFcQLzKDcwI",
    "outputId": "9c1395f7-502f-4022-d3c9-1e65d728fa75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 543.866680\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 187.092402\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 174.154063\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 168.021270\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 169.328477\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 153.925439\n",
      "====> Epoch: 1 Average loss: 179.5390\n",
      "====> Epoch: 1 Average reconstruction loss: 175.5682\n",
      "====> Epoch: 1 Average KL divergence: 3.9708\n",
      "====> Test Epoch: 1 Average loss: 161.5768\n",
      "====> Test Epoch: 1 Average reconstruction loss: 156.5050\n",
      "====> Test Epoch: 1 Average KL divergence: 5.0717\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 155.469297\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 154.607188\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 161.130205\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 155.359814\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 159.959678\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 159.806875\n",
      "====> Epoch: 2 Average loss: 157.4206\n",
      "====> Epoch: 2 Average reconstruction loss: 151.9717\n",
      "====> Epoch: 2 Average KL divergence: 5.4489\n",
      "====> Test Epoch: 2 Average loss: 154.6701\n",
      "====> Test Epoch: 2 Average reconstruction loss: 149.3267\n",
      "====> Test Epoch: 2 Average KL divergence: 5.3434\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 159.962822\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 150.782539\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 148.470508\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 152.953506\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 144.013291\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 151.557969\n",
      "====> Epoch: 3 Average loss: 152.9693\n",
      "====> Epoch: 3 Average reconstruction loss: 147.2508\n",
      "====> Epoch: 3 Average KL divergence: 5.7186\n",
      "====> Test Epoch: 3 Average loss: 151.7023\n",
      "====> Test Epoch: 3 Average reconstruction loss: 146.0322\n",
      "====> Test Epoch: 3 Average KL divergence: 5.6701\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 155.859551\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 151.660947\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 145.848936\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 148.331094\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 152.320508\n"
     ]
    }
   ],
   "source": [
    "# Lists to store losses for each epoch\n",
    "train_losses = []\n",
    "recon_losses = []\n",
    "kl_divergences = []\n",
    "\n",
    "# Lists to store test losses for each epoch\n",
    "test_losses = []\n",
    "test_recon_losses = []\n",
    "test_kl_divergences = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 15 # Set the number of epochs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Train\n",
    "    avg_loss, avg_recon_loss, avg_kl_loss = train(epoch, device)\n",
    "    train_losses.append(avg_loss)\n",
    "    recon_losses.append(avg_recon_loss)\n",
    "    kl_divergences.append(avg_kl_loss)\n",
    "    #Test\n",
    "    avg_test_loss, avg_test_recon_loss, avg_test_kl_loss = test(epoch, device)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    test_recon_losses.append(avg_test_recon_loss)\n",
    "    test_kl_divergences.append(avg_test_kl_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "twqPW-T5ELYB",
    "outputId": "2618a6ed-efb7-4c97-f325-560a8254cd27"
   },
   "outputs": [],
   "source": [
    "# Plot the losses\n",
    "plot_losses(train_losses, recon_losses, kl_divergences)\n",
    "plot_losses(test_losses, test_recon_losses, test_kl_divergences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4I9kTCmVBsp9",
    "outputId": "5adc5b78-47f6-4730-a17e-698207ec5730"
   },
   "outputs": [],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753
    },
    "id": "yOslxSHL9AvN",
    "outputId": "cec704c5-ee17-4c0d-b627-e3d9216d36a2"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "def plot_latent_space(vae, data_loader, device, num_samples=1000):\n",
    "    vae.eval()\n",
    "\n",
    "    latent_vars = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, label in data_loader:\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, log_var = vae(data)\n",
    "            latent_vars.append(mu.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "\n",
    "            # Break after collecting enough samples\n",
    "            if len(np.concatenate(latent_vars)) >= num_samples:\n",
    "                break\n",
    "\n",
    "    # Concatenate all collected latent variables and labels\n",
    "    latent_vars = np.concatenate(latent_vars)[:num_samples]\n",
    "    labels = np.concatenate(labels)[:num_samples]\n",
    "\n",
    "    # Perform t-SNE for dimensionality reduction\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    latent_2d = tsne.fit_transform(latent_vars)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=labels, cmap='viridis', s=5)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title('Latent Space Visualization')\n",
    "    plt.xlabel('t-SNE 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# This is the umap function in case the installation does not work use t-SNE\n",
    "def plot_latent_space(vae, data_loader, device, num_samples=1000):\n",
    "    vae.eval()\n",
    "\n",
    "    latent_vars = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, label in data_loader:\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, log_var = vae(data)\n",
    "            latent_vars.append(mu.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "\n",
    "            # Break after collecting enough samples\n",
    "            if len(np.concatenate(latent_vars)) >= num_samples:\n",
    "                break\n",
    "\n",
    "    # Concatenate all collected latent variables and labels\n",
    "    latent_vars = np.concatenate(latent_vars)[:num_samples]\n",
    "    labels = np.concatenate(labels)[:num_samples]\n",
    "\n",
    "    # Perform UMAP for dimensionality reduction\n",
    "    umap_model = umap.UMAP(n_components=2, random_state=0)\n",
    "    latent_2d = umap_model.fit_transform(latent_vars)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=labels, cmap='viridis', s=5)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title('Latent Space Visualization (UMAP)')\n",
    "    plt.xlabel('UMAP Component 1')\n",
    "    plt.ylabel('UMAP Component 2')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the latent space for training\n",
    "plot_latent_space(vae, train_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753
    },
    "id": "22MZrefR9u60",
    "outputId": "efa1b2c5-e223-4eed-d20c-d7e041de8772"
   },
   "outputs": [],
   "source": [
    "# Plot latent space for test\n",
    "plot_latent_space(vae, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "###0) Training : Find a good fit\n",
    "\n",
    "Determine how many epochs are necessary to get a latent space that represents the data well. You can do this visually by checking that the latent space presents cluster of classes that are distinct. If you want to quantify yoyu can do this by running a K-means clustering algorithm and finding optimal cluster assignment based on the amount of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Experiment with architecture\n",
    "Experiment with the number of layers and their units in order to improve the reconstructions and latent representation. What solution did you find the best and why? (HINT: you will need to change the class VAE(nn.Module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Dimensionality of the latent space\n",
    "Increase the number of units in the latent layer. Does it increase the models representational power and how can you see and explain this? How does this affect the quality of the reconstructions? HINT: You can visualize the latent space in 2D by transforming z to a lower dimensional representation with PCA or UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Visualizing the latent space\n",
    " Do you see any differences in the latent space when doing the visualization with UMAP or PCA ? Why do you think this is ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) EXTRA : Using the latent space for prediction\n",
    " Use the latent space as features to predict the the number of the observation compare it to using the whole data. If you did a k-means clustering in the first question you can use it here to quantify the quality of the latent space. If you prefer it you can use the latent space as features in a neural network. Below you will find a nn that works on the MNIST dataset, it's up to you to make it work on the latent space as an input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a64s9BMn6E9A"
   },
   "source": [
    "### 1) Experiment with architecture\n",
    "Experiment with the number of layers and their units in order to improve the reconstructions and latent representation. What solution did you find the best and why? (HINT: you will need to change the class VAE(nn.Module))\n",
    "\n",
    "###2) Dimensionality of the latent space\n",
    "Increase the number of units in the latent layer. Does it increase the models representational power and how can you see and explain this? How does this affect the quality of the reconstructions? HINT: You can visualize the latent space in 2D by transforming z to a lower dimensional representation with PCA or UMAP.\n",
    "\n",
    "### 3) Visualizing the latent space\n",
    " Do you see any differences in the latent space when doing the visualization with UMAP or PCA ? Why do you think this is ?\n",
    "\n",
    "### 4) EXTRA : Using the latent space for prediction\n",
    " Use the latent space as features to predict the the number of the observation compare it to using the whole data. If you did a k-means clustering in the first question you can use it here to quantify the quality of the latent space. If you prefer it you can use the latent space as features in a neural network. Below you will find a nn that works on the MNIST dataset, it's up to you to make it work on the latent space as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHU7w0Ns6R-X"
   },
   "outputs": [],
   "source": [
    "# Question 2 (help)\n",
    "\n",
    "# Example code for PCA.\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# pca.fit(X)\n",
    "# pca.transform(X)\n",
    "\n",
    "# You will need to incorporate the PCA piece in the plotting function of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 961
    },
    "id": "7xKOyy3VAgpy",
    "outputId": "b6875ea0-4787-4639-b9ae-24ad5fddf860"
   },
   "outputs": [],
   "source": [
    "# This is the code to predict the class from the MNIST dataset, try to build a NN that predicts this from the latent space instead of the whole feature space and compare the results\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load and Preprocess Data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 2. Define the Neural Network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)  # Fully connected layer (input: 784, output: 128)\n",
    "        self.fc2 = nn.Linear(128, 64)     # Fully connected layer (input: 128, output: 64)\n",
    "        self.fc3 = nn.Linear(64, 10)      # Fully connected layer (input: 64, output: 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Flatten the input\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU activation function\n",
    "        x = torch.relu(self.fc2(x))  # Apply ReLU activation function\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "model = SimpleNN()\n",
    "\n",
    "# 3. Define the Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimizer\n",
    "\n",
    "# 4. Train the Model\n",
    "def train(num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "# 5. Evaluate the Model\n",
    "def evaluate():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Train and evaluate the model\n",
    "train(num_epochs=5)\n",
    "evaluate()\n",
    "\n",
    "# Plot some test images with their predictions\n",
    "def plot_predictions():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Plot the first 10 images, their predicted labels, and the true labels\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        for i in range(10):\n",
    "            ax = fig.add_subplot(2, 5, i+1)\n",
    "            ax.imshow(images[i].numpy().squeeze(), cmap='gray')\n",
    "            ax.set_title(f'Pred: {predicted[i].item()}\\nTrue: {labels[i].item()}')\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Plot predictions\n",
    "plot_predictions()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
